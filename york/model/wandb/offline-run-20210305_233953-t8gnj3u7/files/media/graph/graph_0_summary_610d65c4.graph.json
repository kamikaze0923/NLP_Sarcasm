{"format": "torch", "nodes": [{"name": "model", "id": 140045483893712, "class_name": "GPT2LMHeadModel(\n  (transformer): GPT2Model(\n    (wte): Embedding(50261, 768)\n    (wpe): Embedding(1024, 768)\n    (drop): Dropout(p=0.1, inplace=False)\n    (h): ModuleList(\n      (0): Block(\n        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (attn): Attention(\n          (c_attn): Conv1D()\n          (c_proj): Conv1D()\n          (attn_dropout): Dropout(p=0.1, inplace=False)\n          (resid_dropout): Dropout(p=0.1, inplace=False)\n        )\n        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (mlp): MLP(\n          (c_fc): Conv1D()\n          (c_proj): Conv1D()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (1): Block(\n        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (attn): Attention(\n          (c_attn): Conv1D()\n          (c_proj): Conv1D()\n          (attn_dropout): Dropout(p=0.1, inplace=False)\n          (resid_dropout): Dropout(p=0.1, inplace=False)\n        )\n        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (mlp): MLP(\n          (c_fc): Conv1D()\n          (c_proj): Conv1D()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (2): Block(\n        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (attn): Attention(\n          (c_attn): Conv1D()\n          (c_proj): Conv1D()\n          (attn_dropout): Dropout(p=0.1, inplace=False)\n          (resid_dropout): Dropout(p=0.1, inplace=False)\n        )\n        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (mlp): MLP(\n          (c_fc): Conv1D()\n          (c_proj): Conv1D()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (3): Block(\n        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (attn): Attention(\n          (c_attn): Conv1D()\n          (c_proj): Conv1D()\n          (attn_dropout): Dropout(p=0.1, inplace=False)\n          (resid_dropout): Dropout(p=0.1, inplace=False)\n        )\n        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (mlp): MLP(\n          (c_fc): Conv1D()\n          (c_proj): Conv1D()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (4): Block(\n        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (attn): Attention(\n          (c_attn): Conv1D()\n          (c_proj): Conv1D()\n          (attn_dropout): Dropout(p=0.1, inplace=False)\n          (resid_dropout): Dropout(p=0.1, inplace=False)\n        )\n        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (mlp): MLP(\n          (c_fc): Conv1D()\n          (c_proj): Conv1D()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (5): Block(\n        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (attn): Attention(\n          (c_attn): Conv1D()\n          (c_proj): Conv1D()\n          (attn_dropout): Dropout(p=0.1, inplace=False)\n          (resid_dropout): Dropout(p=0.1, inplace=False)\n        )\n        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (mlp): MLP(\n          (c_fc): Conv1D()\n          (c_proj): Conv1D()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (6): Block(\n        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (attn): Attention(\n          (c_attn): Conv1D()\n          (c_proj): Conv1D()\n          (attn_dropout): Dropout(p=0.1, inplace=False)\n          (resid_dropout): Dropout(p=0.1, inplace=False)\n        )\n        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (mlp): MLP(\n          (c_fc): Conv1D()\n          (c_proj): Conv1D()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (7): Block(\n        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (attn): Attention(\n          (c_attn): Conv1D()\n          (c_proj): Conv1D()\n          (attn_dropout): Dropout(p=0.1, inplace=False)\n          (resid_dropout): Dropout(p=0.1, inplace=False)\n        )\n        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (mlp): MLP(\n          (c_fc): Conv1D()\n          (c_proj): Conv1D()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (8): Block(\n        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (attn): Attention(\n          (c_attn): Conv1D()\n          (c_proj): Conv1D()\n          (attn_dropout): Dropout(p=0.1, inplace=False)\n          (resid_dropout): Dropout(p=0.1, inplace=False)\n        )\n        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (mlp): MLP(\n          (c_fc): Conv1D()\n          (c_proj): Conv1D()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (9): Block(\n        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (attn): Attention(\n          (c_attn): Conv1D()\n          (c_proj): Conv1D()\n          (attn_dropout): Dropout(p=0.1, inplace=False)\n          (resid_dropout): Dropout(p=0.1, inplace=False)\n        )\n        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (mlp): MLP(\n          (c_fc): Conv1D()\n          (c_proj): Conv1D()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (10): Block(\n        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (attn): Attention(\n          (c_attn): Conv1D()\n          (c_proj): Conv1D()\n          (attn_dropout): Dropout(p=0.1, inplace=False)\n          (resid_dropout): Dropout(p=0.1, inplace=False)\n        )\n        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (mlp): MLP(\n          (c_fc): Conv1D()\n          (c_proj): Conv1D()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (11): Block(\n        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (attn): Attention(\n          (c_attn): Conv1D()\n          (c_proj): Conv1D()\n          (attn_dropout): Dropout(p=0.1, inplace=False)\n          (resid_dropout): Dropout(p=0.1, inplace=False)\n        )\n        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (mlp): MLP(\n          (c_fc): Conv1D()\n          (c_proj): Conv1D()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n    )\n    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n  )\n  (lm_head): Linear(in_features=768, out_features=50261, bias=False)\n)", "parameters": [["transformer.wte.weight", [50261, 768]], ["transformer.wpe.weight", [1024, 768]], ["transformer.h.0.ln_1.weight", [768]], ["transformer.h.0.ln_1.bias", [768]], ["transformer.h.0.attn.c_attn.weight", [768, 2304]], ["transformer.h.0.attn.c_attn.bias", [2304]], ["transformer.h.0.attn.c_proj.weight", [768, 768]], ["transformer.h.0.attn.c_proj.bias", [768]], ["transformer.h.0.ln_2.weight", [768]], ["transformer.h.0.ln_2.bias", [768]], ["transformer.h.0.mlp.c_fc.weight", [768, 3072]], ["transformer.h.0.mlp.c_fc.bias", [3072]], ["transformer.h.0.mlp.c_proj.weight", [3072, 768]], ["transformer.h.0.mlp.c_proj.bias", [768]], ["transformer.h.1.ln_1.weight", [768]], ["transformer.h.1.ln_1.bias", [768]], ["transformer.h.1.attn.c_attn.weight", [768, 2304]], ["transformer.h.1.attn.c_attn.bias", [2304]], ["transformer.h.1.attn.c_proj.weight", [768, 768]], ["transformer.h.1.attn.c_proj.bias", [768]], ["transformer.h.1.ln_2.weight", [768]], ["transformer.h.1.ln_2.bias", [768]], ["transformer.h.1.mlp.c_fc.weight", [768, 3072]], ["transformer.h.1.mlp.c_fc.bias", [3072]], ["transformer.h.1.mlp.c_proj.weight", [3072, 768]], ["transformer.h.1.mlp.c_proj.bias", [768]], ["transformer.h.2.ln_1.weight", [768]], ["transformer.h.2.ln_1.bias", [768]], ["transformer.h.2.attn.c_attn.weight", [768, 2304]], ["transformer.h.2.attn.c_attn.bias", [2304]], ["transformer.h.2.attn.c_proj.weight", [768, 768]], ["transformer.h.2.attn.c_proj.bias", [768]], ["transformer.h.2.ln_2.weight", [768]], ["transformer.h.2.ln_2.bias", [768]], ["transformer.h.2.mlp.c_fc.weight", [768, 3072]], ["transformer.h.2.mlp.c_fc.bias", [3072]], ["transformer.h.2.mlp.c_proj.weight", [3072, 768]], ["transformer.h.2.mlp.c_proj.bias", [768]], ["transformer.h.3.ln_1.weight", [768]], ["transformer.h.3.ln_1.bias", [768]], ["transformer.h.3.attn.c_attn.weight", [768, 2304]], ["transformer.h.3.attn.c_attn.bias", [2304]], ["transformer.h.3.attn.c_proj.weight", [768, 768]], ["transformer.h.3.attn.c_proj.bias", [768]], ["transformer.h.3.ln_2.weight", [768]], ["transformer.h.3.ln_2.bias", [768]], ["transformer.h.3.mlp.c_fc.weight", [768, 3072]], ["transformer.h.3.mlp.c_fc.bias", [3072]], ["transformer.h.3.mlp.c_proj.weight", [3072, 768]], ["transformer.h.3.mlp.c_proj.bias", [768]], ["transformer.h.4.ln_1.weight", [768]], ["transformer.h.4.ln_1.bias", [768]], ["transformer.h.4.attn.c_attn.weight", [768, 2304]], ["transformer.h.4.attn.c_attn.bias", [2304]], ["transformer.h.4.attn.c_proj.weight", [768, 768]], ["transformer.h.4.attn.c_proj.bias", [768]], ["transformer.h.4.ln_2.weight", [768]], ["transformer.h.4.ln_2.bias", [768]], ["transformer.h.4.mlp.c_fc.weight", [768, 3072]], ["transformer.h.4.mlp.c_fc.bias", [3072]], ["transformer.h.4.mlp.c_proj.weight", [3072, 768]], ["transformer.h.4.mlp.c_proj.bias", [768]], ["transformer.h.5.ln_1.weight", [768]], ["transformer.h.5.ln_1.bias", [768]], ["transformer.h.5.attn.c_attn.weight", [768, 2304]], ["transformer.h.5.attn.c_attn.bias", [2304]], ["transformer.h.5.attn.c_proj.weight", [768, 768]], ["transformer.h.5.attn.c_proj.bias", [768]], ["transformer.h.5.ln_2.weight", [768]], ["transformer.h.5.ln_2.bias", [768]], ["transformer.h.5.mlp.c_fc.weight", [768, 3072]], ["transformer.h.5.mlp.c_fc.bias", [3072]], ["transformer.h.5.mlp.c_proj.weight", [3072, 768]], ["transformer.h.5.mlp.c_proj.bias", [768]], ["transformer.h.6.ln_1.weight", [768]], ["transformer.h.6.ln_1.bias", [768]], ["transformer.h.6.attn.c_attn.weight", [768, 2304]], ["transformer.h.6.attn.c_attn.bias", [2304]], ["transformer.h.6.attn.c_proj.weight", [768, 768]], ["transformer.h.6.attn.c_proj.bias", [768]], ["transformer.h.6.ln_2.weight", [768]], ["transformer.h.6.ln_2.bias", [768]], ["transformer.h.6.mlp.c_fc.weight", [768, 3072]], ["transformer.h.6.mlp.c_fc.bias", [3072]], ["transformer.h.6.mlp.c_proj.weight", [3072, 768]], ["transformer.h.6.mlp.c_proj.bias", [768]], ["transformer.h.7.ln_1.weight", [768]], ["transformer.h.7.ln_1.bias", [768]], ["transformer.h.7.attn.c_attn.weight", [768, 2304]], ["transformer.h.7.attn.c_attn.bias", [2304]], ["transformer.h.7.attn.c_proj.weight", [768, 768]], ["transformer.h.7.attn.c_proj.bias", [768]], ["transformer.h.7.ln_2.weight", [768]], ["transformer.h.7.ln_2.bias", [768]], ["transformer.h.7.mlp.c_fc.weight", [768, 3072]], ["transformer.h.7.mlp.c_fc.bias", [3072]], ["transformer.h.7.mlp.c_proj.weight", [3072, 768]], ["transformer.h.7.mlp.c_proj.bias", [768]], ["transformer.h.8.ln_1.weight", [768]], ["transformer.h.8.ln_1.bias", [768]], ["transformer.h.8.attn.c_attn.weight", [768, 2304]], ["transformer.h.8.attn.c_attn.bias", [2304]], ["transformer.h.8.attn.c_proj.weight", [768, 768]], ["transformer.h.8.attn.c_proj.bias", [768]], ["transformer.h.8.ln_2.weight", [768]], ["transformer.h.8.ln_2.bias", [768]], ["transformer.h.8.mlp.c_fc.weight", [768, 3072]], ["transformer.h.8.mlp.c_fc.bias", [3072]], ["transformer.h.8.mlp.c_proj.weight", [3072, 768]], ["transformer.h.8.mlp.c_proj.bias", [768]], ["transformer.h.9.ln_1.weight", [768]], ["transformer.h.9.ln_1.bias", [768]], ["transformer.h.9.attn.c_attn.weight", [768, 2304]], ["transformer.h.9.attn.c_attn.bias", [2304]], ["transformer.h.9.attn.c_proj.weight", [768, 768]], ["transformer.h.9.attn.c_proj.bias", [768]], ["transformer.h.9.ln_2.weight", [768]], ["transformer.h.9.ln_2.bias", [768]], ["transformer.h.9.mlp.c_fc.weight", [768, 3072]], ["transformer.h.9.mlp.c_fc.bias", [3072]], ["transformer.h.9.mlp.c_proj.weight", [3072, 768]], ["transformer.h.9.mlp.c_proj.bias", [768]], ["transformer.h.10.ln_1.weight", [768]], ["transformer.h.10.ln_1.bias", [768]], ["transformer.h.10.attn.c_attn.weight", [768, 2304]], ["transformer.h.10.attn.c_attn.bias", [2304]], ["transformer.h.10.attn.c_proj.weight", [768, 768]], ["transformer.h.10.attn.c_proj.bias", [768]], ["transformer.h.10.ln_2.weight", [768]], ["transformer.h.10.ln_2.bias", [768]], ["transformer.h.10.mlp.c_fc.weight", [768, 3072]], ["transformer.h.10.mlp.c_fc.bias", [3072]], ["transformer.h.10.mlp.c_proj.weight", [3072, 768]], ["transformer.h.10.mlp.c_proj.bias", [768]], ["transformer.h.11.ln_1.weight", [768]], ["transformer.h.11.ln_1.bias", [768]], ["transformer.h.11.attn.c_attn.weight", [768, 2304]], ["transformer.h.11.attn.c_attn.bias", [2304]], ["transformer.h.11.attn.c_proj.weight", [768, 768]], ["transformer.h.11.attn.c_proj.bias", [768]], ["transformer.h.11.ln_2.weight", [768]], ["transformer.h.11.ln_2.bias", [768]], ["transformer.h.11.mlp.c_fc.weight", [768, 3072]], ["transformer.h.11.mlp.c_fc.bias", [3072]], ["transformer.h.11.mlp.c_proj.weight", [3072, 768]], ["transformer.h.11.mlp.c_proj.bias", [768]], ["transformer.ln_f.weight", [768]], ["transformer.ln_f.bias", [768]]], "output_shape": [[[[0], [0], [0], 0], [0, 0, [0], [0], [0], 0], [[0], [0], 0, 0, [0], [0], [0], [0], 0, [0], 0, 0, [0], 0, 0]]], "num_parameters": [38600448, 786432, 768, 768, 1769472, 2304, 589824, 768, 768, 768, 2359296, 3072, 2359296, 768, 768, 768, 1769472, 2304, 589824, 768, 768, 768, 2359296, 3072, 2359296, 768, 768, 768, 1769472, 2304, 589824, 768, 768, 768, 2359296, 3072, 2359296, 768, 768, 768, 1769472, 2304, 589824, 768, 768, 768, 2359296, 3072, 2359296, 768, 768, 768, 1769472, 2304, 589824, 768, 768, 768, 2359296, 3072, 2359296, 768, 768, 768, 1769472, 2304, 589824, 768, 768, 768, 2359296, 3072, 2359296, 768, 768, 768, 1769472, 2304, 589824, 768, 768, 768, 2359296, 3072, 2359296, 768, 768, 768, 1769472, 2304, 589824, 768, 768, 768, 2359296, 3072, 2359296, 768, 768, 768, 1769472, 2304, 589824, 768, 768, 768, 2359296, 3072, 2359296, 768, 768, 768, 1769472, 2304, 589824, 768, 768, 768, 2359296, 3072, 2359296, 768, 768, 768, 1769472, 2304, 589824, 768, 768, 768, 2359296, 3072, 2359296, 768, 768, 768, 1769472, 2304, 589824, 768, 768, 768, 2359296, 3072, 2359296, 768, 768, 768]}], "edges": []}